{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"111-Pytorch tutorial.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zDzZezp5x02B"},"source":["# Pytorch tutorial\n"]},{"cell_type":"markdown","metadata":{"id":"qMhmEs1Px02E"},"source":["## What is pytorch?\n","- Numpy를 대체하며 GPU연산을 지원하는 tensor 구조 지원  \n","CUDA(NDVIA에서 gpu를 통한 연산을 위해 만든 API)와 cuDNN(CUDA를 활용하여 딥러닝 gpu연산을 지원하는 API)을 활용하여 연산 가속  \n","일반적으로 CUDA와 cuDNN을 활용하는 연산은 CPU연산의 15배정도 가속을 가져옴. \n","\n","\n","- backward() 함수를 통한 그래프 미분 연산 지원"]},{"cell_type":"markdown","metadata":{"id":"f6CpHw3Gx02F"},"source":["## Pytorch vs Tensorflow"]},{"cell_type":"markdown","metadata":{"id":"Ti5q8SOVx02F"},"source":["#### 둘 모두 GPU를 활용하는 framework\n","- Tensorflow  \n","`Define and Run`방식  \n","연산 그래프를 미리 만들어두고, 실제 연산시 값을 전달하여 결과를 얻음(정적)  \n","직관적이지 않고 그래프를 정의하는 부분과 실행하는 부분이 분리되어 코드가 길어짐  \n","최적화에서 장점\n","\n","\n","- Pytorch  \n","`Define by Run` 방식  \n","연산 그래프를 미리 만들어두지 않고 값이 할당되어 전달되는 과정에서 그래프가 작성(동적)  \n","직관적이고 간단한 코드  \n","(Pytorch측의 주장으로는)Tensorflow보다 평균 2.5배정도 빠른 속도(적어도 밀리지는 않음)"]},{"cell_type":"markdown","metadata":{"id":"--2PsdO5x02F"},"source":["## Tensor"]},{"cell_type":"markdown","metadata":{"id":"sl1Jxu8Ox02G"},"source":["Tensor: Numpy의 ndarray와 유사한 matrix자료구조. GPU연산 가속이 가능"]},{"cell_type":"code","metadata":{"id":"7RLJYZlRx02G"},"source":["import torch\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xbEY07RKx02G"},"source":["### Tensor 생성"]},{"cell_type":"code","metadata":{"id":"dkopew_ix02H"},"source":["not_initialized = torch.empty(3, 4)\n","not_initialized"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xyx150Ppx02H"},"source":["random_initialized = torch.rand(3, 4)\n","random_initialized"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1thWlgxx02I"},"source":["zero_initialized = torch.zeros(3, 4)\n","zero_initialized"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idNHRz3px02I"},"source":["list_initialized = torch.tensor([[1, 2],[3, 4]])\n","list_initialized"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLVVxFE5x02J"},"source":["arange_lnitiaized = torch.arange(10)\n","arange_lnitiaized"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"338U0oH5x02J"},"source":["### Tensor와 numpy간의 변환"]},{"cell_type":"code","metadata":{"id":"iNnT6_2Ix02J"},"source":["x = torch.ones(10)\n","x, type(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-KguJxwx02K"},"source":["y = x.numpy()\n","y, type(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFWL03tEx02K"},"source":["z = torch.from_numpy(y)\n","z"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"17AkaO-rx02L"},"source":["#### 주의사항 - tensor와 ndarray는 메모리공간을 공유함"]},{"cell_type":"code","metadata":{"id":"QhFw8HxRx02M"},"source":["x.add_(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJycARKlx02N"},"source":["x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXRTal76x02O"},"source":["y, z"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uvcc7CBKx02O"},"source":["### Tensor 특성"]},{"cell_type":"code","metadata":{"id":"AG3JYwnzx02O"},"source":["list_initialized.shape, list_initialized.ndim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucigRgKUx02P"},"source":["\n","list_initialized.size()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B90aXEdUx02P"},"source":["### Tensor reshape vs view"]},{"cell_type":"markdown","metadata":{"id":"dU3aoArKx02P"},"source":["-  두 함수는 기본적으로 같은 기능을 하나, view는 shallow copy이다.\n","-  그러나, reshape이 deep copy인 것은 아니다. reshape은 상황에 따라 deep/shallow를 넘나든다.\n","-  Reshape은 Contiguous한 operate를 지원하나, view는 지원하지 않는다."]},{"cell_type":"code","metadata":{"id":"UmoUKOCMx02Q"},"source":["list_initialized.t()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"izUaMP4_x02Q"},"source":["list_initialized.t().reshape(-1, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdmEsITax02Q"},"source":["list_initialized.t().view(-1, 1) # Error!"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"raF8YpmQx02R"},"source":["### Tensor의 배열 연산"]},{"cell_type":"markdown","metadata":{"id":"9CcCJ8lvx02R"},"source":["인덱싱, 슬라이싱, 선형대수 등 각종 연산 numpy와 동일하게 수행 가능"]},{"cell_type":"markdown","metadata":{"id":"JUfLQ1FPx02R"},"source":["#### 기본연산"]},{"cell_type":"code","metadata":{"id":"QkMcYGOJx02R"},"source":["x = torch.arange(1, 11).reshape(2, 5)\n","y = torch.arange(1, 20, step=2).reshape(2, 5)\n","x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHS53G0ix02R"},"source":["x + y, torch.add(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1mMo_Whx02S"},"source":["x - y, torch.sub(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzHgtEaqx02S"},"source":["x * y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIGgmuq7x02T"},"source":["y % x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lL2LSkECx02T"},"source":["#### 행렬곱"]},{"cell_type":"code","metadata":{"id":"29IFDX0ix02V"},"source":["x.matmul(y.reshape(5, 2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q2We-2vcx02W"},"source":["#### 바꿔치기(in-place) 와 반환하기(out-of-place)"]},{"cell_type":"code","metadata":{"id":"8HG01Ygxx02W"},"source":["x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j1N3zBVWx02X"},"source":["x.add(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oisQKd1ex02X"},"source":["x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxYWAxDrx02X"},"source":["x.add_(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVu26uLTx02Y"},"source":["x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4a5aKLBXx02Y"},"source":["#### 헷갈리는 경우"]},{"cell_type":"code","metadata":{"id":"NnbIKWYMx02Y"},"source":["z = x.numpy()\n","x = x.add(3)\n","print('x:',x)\n","print('z:',z)\n","print('========================')\n","x.add_(3)\n","print('x:', x)\n","print('z:', z)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hX1Sm7uUx02Z"},"source":["#### Indexing and slicing"]},{"cell_type":"code","metadata":{"id":"2_V9hjIlx02Z"},"source":["x[0, 3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YX2x4191x02a"},"source":["x[:, 1:4]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CEIa8Tfdx02a"},"source":["### Aggregation"]},{"cell_type":"code","metadata":{"id":"6DvHNt9Fx02a"},"source":["x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_UdSVccx02a"},"source":["x.sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOgoUkzwx02b"},"source":["x.sum(dim=0), x.sum(axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-tj79e6ox02b"},"source":["x.sum(dim=1), x.sum(axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qxcN0l0Ex02b"},"source":["#### Can't use mean() on integers"]},{"cell_type":"code","metadata":{"id":"K4ZdPa49x02b"},"source":["x.dtype, x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OsawsBLqx02b"},"source":["try:\n","    print(x.mean(dim=0))\n","except Exception as exc:\n","    print(exc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZKxc0Jy_x02c"},"source":["# x = torch.arange(1, 11, dtype=float).reshape(2, 5)\n","x = x.float()\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XKjDzMrAx02c"},"source":["x.mean(), x.mean(dim=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pNcKPozYx02d"},"source":["### Broadcasting"]},{"cell_type":"code","metadata":{"id":"YLS1jVukx02d"},"source":["x = torch.arange(1, 11).reshape(1, -1)\n","y = torch.arange(1, 20, step=2).reshape(-1, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"97FLUA7tx02d"},"source":["x + y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"527oICN2x02e"},"source":["## AUTOGRAD: 자동미분"]},{"cell_type":"markdown","metadata":{"id":"TipK2n9dx02e"},"source":["`pytorch` 신경망의 중심. `backward()`를 가능케 하는 패키지  \n","`Tensor`의 모든 연산에 대해 자동 미분을 제공"]},{"cell_type":"markdown","metadata":{"id":"1h8J2XqZx02e"},"source":["`pytorch.Tensor` class에는 `.required_grad` 속성이 존재  \n","`.required_grad`를 True로 세팅하면 해당 tensor를 기반으로 이루어신 모든 연산을 추적(track)하기 시작함  \n","모든 연산이 완료된 후, `backward()`를 호출하면 모든 gradient가 자동으로 계산(`Tensor.grad` 속성에 gradient가 누적됨)"]},{"cell_type":"markdown","metadata":{"id":"eJA-Xb96x02e"},"source":["Autograd의 다른 중요 class는 `Function`class  \n","`Tensor`와 `Function`class는 연결되어 있으며, 모든 연산을 encode하여 acyclic graph를 생성  \n","각각의 tensor는 `.grad_fn`속성을 가지며 이는 `Tensor`를 생성한 `Function`을 참조함"]},{"cell_type":"code","metadata":{"id":"umHK-SP-x02e"},"source":["x = torch.ones(5, 2, requires_grad=True)\n","# x = torch.arange(10, dtype=torch.float32).reshape(5, 2)\n","# x.requires_grad = True\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A72TgGEEx02f"},"source":["y = x + 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJSOLt7Mx02f"},"source":["y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bK2vHwmIx02f"},"source":["y는 연산의 결과로 생성된 tensor이므로 grad_fn을 가짐"]},{"cell_type":"code","metadata":{"id":"5X8FtJA5x02f"},"source":["y.grad_fn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5BR5Y4Ox02f"},"source":["z = y * y * 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_zo75sMx02g"},"source":["out = z.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m18Qlq_yx02g"},"source":["z, out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9OQiCNYMx02g"},"source":["### 변화도(Gradient) 계산)"]},{"cell_type":"code","metadata":{"id":"-WF4dxKwx02g"},"source":["out.backward(retain_graph=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1q0ncMddx02g"},"source":["print(x.grad)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUNBsKY0x02h"},"source":["#### Jacobian matrix 활용"]},{"cell_type":"code","metadata":{"id":"nenEEaCVx02h"},"source":["x = torch.ones(5, 2, requires_grad=True)\n","y = x + 10\n","z = y * y * 10\n","out = z.mean(axis=1)\n","out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1LWujRtLMwse"},"source":["x = torch.ones(5, 2, requires_grad=True)\n","y = x + 10\n","y = y * y * 10\n","y = y.mean(axis=1)\n","y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HkcDAjax02h"},"source":["y.backward(torch.tensor([1., 3.,1.,1.,1.]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yo_GWxSEx02h"},"source":["print(x.grad)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JIERUbPgx02h"},"source":["## DataLoader"]},{"cell_type":"markdown","metadata":{"id":"8GDKLJxKx02i"},"source":["torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False,  num_workers=0,...)"]},{"cell_type":"markdown","metadata":{"id":"USIrh6pKx02i"},"source":["데이터를 학습모델에 통째로 넣지 않고 batch 단위로 나누어 학습시킬 때 활용.  \n","모든 데이터를 나누고 나눈 데이터를 차례로 넣어주는 과정을 대신해줌\n","- 용어  \n"," - epoch: 모든 training data 혹은 모든 training data를 학습시킨 상태\n"," - batch: batch_size만큼의 training data만 학습시키기 위한 소분 데이터\n"]},{"cell_type":"code","metadata":{"id":"2Jryz2s4x02i"},"source":["x = [[73, 80, 75],\n","   [93, 88, 93],\n","   [89, 91, 90],\n","   [96, 98, 100],\n","   [73, 66, 70]]\n","x = torch.FloatTensor(x)\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SKPcNX-x02i"},"source":["data_loader = torch.utils.data.DataLoader(x,\n","                            batch_size=2, \n","                            shuffle=True, \n","                            num_workers=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBjYbuyYx02i"},"source":["epochs = 2\n","for epoch in range(epochs):\n","    for step, batch in enumerate(data_loader):\n","        print(step, batch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Reyhobgcx02j"},"source":["## CUDA Tensor"]},{"cell_type":"markdown","metadata":{"id":"8Ew2NRLZx02j"},"source":["### GPU로 이동"]},{"cell_type":"code","metadata":{"id":"OUf9Isugx02j"},"source":["if torch.cuda.is_available():\n","    x = x.to(torch.device('cuda'))\n","    print(type(x))\n","    print(x.device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lhTpdfk9x02j"},"source":["#### 생성과 함께 gpu에 할당"]},{"cell_type":"code","metadata":{"id":"hK5_hwHNx02j"},"source":["if torch.cuda.is_available():\n","    k = torch.full((2, 3), 1, device=torch.device('cuda'))\n","    print(type(k))\n","    print(k.device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rntQdD26x02j"},"source":["### CPU로 이동"]},{"cell_type":"code","metadata":{"id":"Hk8l2Z8Hx02k"},"source":["if torch.cuda.is_available():\n","    x = x.to(torch.device('cpu'))\n","    print(type(x))\n","    print(x.device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1yjxyOBWv6zl"},"source":[""],"execution_count":null,"outputs":[]}]}